{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import inspect\n",
    "import logging\n",
    "from mysql import connector\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "class AQ:\n",
    "\n",
    "    # Global constants\n",
    "    WS_PATH = os.path.abspath(\"./\") + os.sep\n",
    "    DB_HOST = \"127.0.0.1\"\n",
    "    DB_USR = \"root\"\n",
    "    DB_PWD = \"!QAZ2wsx#EDC\"\n",
    "    DB_NAME = \"aq\"\n",
    "    \n",
    "    def log(self, msg):\n",
    "        print(msg)\n",
    "        \n",
    "class ML:\n",
    "    def __init__(self, aq):\n",
    "        self.aq = aq\n",
    "    \n",
    "    def get_data(self, code, type):\n",
    "        mysql_connector = connector.connect(host=self.aq.DB_HOST, database=self.aq.DB_NAME,\n",
    "                                            user=self.aq.DB_USR, password=self.aq.DB_PWD)\n",
    "        data = pd.read_sql(\"\"\"SELECT close, high-low as hl, close-open as oc FROM future_trade WHERE code='%s' AND type='%s' \"\"\" % (code, type), \n",
    "                              con=mysql_connector)\n",
    "        data_1 = data.close.diff()\n",
    "        data_1[0] = 0\n",
    "        data_2 = data.hl\n",
    "        data_3 = data.oc\n",
    "        data = pd.DataFrame({\"data_1\":data_1, \"data_2\":data_2, \"data_3\":data_3})\n",
    "        data = pd.DataFrame(preprocessing.normalize(data), columns=[\"data_1\", \"data_2\", \"data_3\"])\n",
    "        mysql_connector.close()\n",
    "        return data\n",
    "    \n",
    "    def get_Y(self, data, lag_1, lag_2, lag_3):\n",
    "        Y = data.data_1[max(lag_1, lag_2, lag_3):]\n",
    "        Y.index = range(len(Y))\n",
    "        Y = Y.apply(lambda x: x >= 0)\n",
    "        return Y\n",
    "\n",
    "    def get_X(self, data, lag_1, lag_2, lag_3):\n",
    "        X = pd.DataFrame(columns=range(lag_1 + lag_2 + lag_3))\n",
    "        for idx, row in data.iterrows():\n",
    "            if idx >= lag_1 and idx >= lag_2 and idx >= lag_3:\n",
    "                data_1 = data.iloc[(idx - lag_1):idx, 0]\n",
    "                data_2 = data.iloc[(idx - lag_2):idx, 1]\n",
    "                data_3 = data.iloc[(idx - lag_3):idx, 2]\n",
    "                xrow = pd.concat([data_1, data_2, data_3], ignore_index=True)\n",
    "                X = X.append(xrow, ignore_index=True)\n",
    "        return X\n",
    "\n",
    "    def cross_check(self, model, k_fold, X, Y):\n",
    "        hit_rate_sum = 0\n",
    "        stride = round(len(Y) / k_fold)\n",
    "        for i in range(0, k_fold):\n",
    "            start = i * stride\n",
    "            stop = i * stride + stride - 1\n",
    "            if (i == k_fold - 1):\n",
    "                stop = len(Y)            \n",
    "            X_test = X[start:stop]\n",
    "            Y_test = Y[start:stop]\n",
    "            if (i == 0):\n",
    "                X_train = X[stop:]\n",
    "                Y_train = Y[stop:]\n",
    "            else:\n",
    "                X_train = pd.concat([X[0:start], X[stop:]])\n",
    "                Y_train = pd.concat([Y[0:start], Y[stop:]])\n",
    "            model.fit(X_train, Y_train)\n",
    "            hit_rate = np.sum(model.predict(X_test) == Y_test) / (stop-start)\n",
    "            hit_rate_sum += hit_rate\n",
    "            #self.aq.log(\"  k_fold=%s, %.2f%s, start=%d, stop=%d, test_len=%d, train_len=%d\" %\n",
    "            #               (i+1, hit_rate*100 , \"%\", start, stop, len(Y_test), len(Y_train)))\n",
    "        return hit_rate_sum/k_fold\n",
    "\n",
    "    def ml(self, code, type, lags, k_fold):\n",
    "        self.aq.log(\"Code=%s, Type=%s, lags=%s, k_fold=%s\" % (code,type,lags,k_fold))\n",
    "        \n",
    "        mysql_connector = connector.connect(host=self.aq.DB_HOST, database=self.aq.DB_NAME,\n",
    "                                            user=self.aq.DB_USR, password=self.aq.DB_PWD)\n",
    "        \n",
    "        data = self.get_data(code, type)\n",
    "\n",
    "        lag_1 = lags[0]\n",
    "        lag_2 = lags[1]\n",
    "        lag_3 = lags[2]\n",
    "        \n",
    "        X = self.get_X(data, lag_1, lag_2, lag_3)\n",
    "        Y = self.get_Y(data, lag_1, lag_2, lag_3)\n",
    "        \n",
    "        \n",
    "        model = ExtraTreesClassifier()\n",
    "        model.fit(X, Y)\n",
    "        self.aq.log(model.feature_importances_)\n",
    "        self.aq.log(\"\")\n",
    "        \n",
    "        self.aq.log(\"Logistic Regression\")\n",
    "        model = LogisticRegression()\n",
    "        hit_rate = self.cross_check(model, k_fold, X, Y)\n",
    "        self.aq.log(\"Average Hit Rate = %g%s\" % (hit_rate*100, \"%\"))\n",
    "        self.aq.log(\" \")\n",
    "        \n",
    "        self.aq.log(\"Naive Bayes\")\n",
    "        model = GaussianNB()\n",
    "        hit_rate = self.cross_check(model, k_fold, X, Y)\n",
    "        self.aq.log(\"Average Hit Rate = %g%s\" % (hit_rate * 100, \"%\"))\n",
    "        self.aq.log(\"\")\n",
    "        \n",
    "        self.aq.log(\"K Neighbors\")\n",
    "        model = KNeighborsClassifier()\n",
    "        hit_rate = self.cross_check(model, k_fold, X, Y)\n",
    "        self.aq.log(\"Average Hit Rate = %g%s\" % (hit_rate * 100, \"%\"))\n",
    "        self.aq.log(\"\")\n",
    "        \n",
    "        self.aq.log(\"Decision Tree\")\n",
    "        model = DecisionTreeClassifier()\n",
    "        hit_rate = self.cross_check(model, k_fold, X, Y)\n",
    "        self.aq.log(\"Average Hit Rate = %g%s\" % (hit_rate * 100, \"%\"))\n",
    "        self.aq.log(\"\")\n",
    "        \n",
    "        self.aq.log(\"Support Vector Machine\")\n",
    "        model = SVC()\n",
    "        hit_rate = self.cross_check(model, k_fold, X, Y)\n",
    "        self.aq.log(\"Average Hit Rate = %g%s\" % (hit_rate * 100, \"%\"))\n",
    "        self.aq.log(\"\")\n",
    "        \n",
    "        mysql_connector.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code=I, Type=d, lags=[1, 1, 1], k_fold=10\n",
      "[ 0.32783942  0.3368371   0.33532348]\n",
      "\n",
      "Logistic Regression\n",
      "Average Hit Rate = 52.2833%\n",
      " \n",
      "Naive Bayes\n",
      "Average Hit Rate = 51.9556%\n",
      "\n",
      "K Neighbors\n",
      "Average Hit Rate = 48.876%\n",
      "\n",
      "Decision Tree\n",
      "Average Hit Rate = 51.1593%\n",
      "\n",
      "Support Vector Machine\n",
      "Average Hit Rate = 50.0403%\n",
      "\n",
      "Code=I, Type=d, lags=[5, 5, 5], k_fold=10\n",
      "[ 0.06025486  0.06645201  0.06586262  0.07436459  0.06250744  0.06256207\n",
      "  0.06641691  0.06521054  0.06527944  0.06575098  0.06452364  0.07180528\n",
      "  0.07221069  0.06749643  0.0693025 ]\n",
      "\n",
      "Logistic Regression\n",
      "Average Hit Rate = 53.5323%\n",
      " \n",
      "Naive Bayes\n",
      "Average Hit Rate = 52.2688%\n",
      "\n",
      "K Neighbors\n",
      "Average Hit Rate = 51.4516%\n",
      "\n",
      "Decision Tree\n",
      "Average Hit Rate = 51.4624%\n",
      "\n",
      "Support Vector Machine\n",
      "Average Hit Rate = 54.3602%\n",
      "\n",
      "Code=I, Type=d, lags=[10, 10, 10], k_fold=10\n",
      "[ 0.03764778  0.03937292  0.03034663  0.034795    0.02369454  0.03600655\n",
      "  0.03493189  0.0379902   0.0392281   0.0270575   0.02834396  0.03574585\n",
      "  0.04245804  0.03221459  0.03404298  0.03152246  0.02675746  0.03531911\n",
      "  0.02830208  0.02998869  0.03782153  0.03520919  0.03285409  0.02481469\n",
      "  0.03582202  0.02927135  0.0319398   0.03705979  0.03871917  0.03072204]\n",
      "\n",
      "Logistic Regression\n",
      "Average Hit Rate = 53.3607%\n",
      " \n",
      "Naive Bayes\n",
      "Average Hit Rate = 54.2034%\n",
      "\n",
      "K Neighbors\n",
      "Average Hit Rate = 50.2305%\n",
      "\n",
      "Decision Tree\n",
      "Average Hit Rate = 49.7618%\n",
      "\n",
      "Support Vector Machine\n",
      "Average Hit Rate = 53.5246%\n",
      "\n",
      "Code=I, Type=d, lags=[20, 20, 20], k_fold=10\n",
      "[ 0.01571855  0.01307265  0.01168993  0.01661075  0.01581188  0.01778885\n",
      "  0.0215191   0.02125213  0.01263858  0.01613698  0.01820026  0.01354638\n",
      "  0.01787145  0.01575371  0.01746732  0.0147778   0.01338893  0.01807885\n",
      "  0.01959406  0.01421084  0.01647912  0.0194556   0.02025491  0.01544079\n",
      "  0.01311522  0.0148713   0.01923025  0.01603146  0.0201078   0.01610699\n",
      "  0.01160017  0.01814667  0.01513635  0.0175482   0.01549407  0.02134801\n",
      "  0.01473252  0.02598529  0.01853953  0.01399332  0.01130985  0.02157428\n",
      "  0.01987507  0.01602729  0.01856374  0.01777388  0.01435791  0.01856654\n",
      "  0.01890979  0.02057217  0.01781177  0.00981062  0.01779936  0.01550776\n",
      "  0.01266247  0.01547288  0.01002428  0.01266673  0.01728085  0.02468621]\n",
      "\n",
      "Logistic Regression\n",
      "Average Hit Rate = 53.5397%\n",
      " \n",
      "Naive Bayes\n",
      "Average Hit Rate = 52.1984%\n",
      "\n",
      "K Neighbors\n",
      "Average Hit Rate = 45.8968%\n",
      "\n",
      "Decision Tree\n",
      "Average Hit Rate = 50.7381%\n",
      "\n",
      "Support Vector Machine\n",
      "Average Hit Rate = 52.0317%\n",
      "\n",
      "Code=I, Type=d, lags=[50, 50, 50], k_fold=10\n",
      "[ 0.00650687  0.00899439  0.01090846  0.00950122  0.00344242  0.00359025\n",
      "  0.00799173  0.00576387  0.00639377  0.00719553  0.00665292  0.00656261\n",
      "  0.00791759  0.00405304  0.00454376  0.00859382  0.00771241  0.00387092\n",
      "  0.00477272  0.00256348  0.00661691  0.00483691  0.00936109  0.00696136\n",
      "  0.00757396  0.00984532  0.00393869  0.00606173  0.00805316  0.00309683\n",
      "  0.00792681  0.01185641  0.00951174  0.00619192  0.00704485  0.00713098\n",
      "  0.00480789  0.00677291  0.00956265  0.00450626  0.00746548  0.00450867\n",
      "  0.01036519  0.00427998  0.00468857  0.0052886   0.00692996  0.00608169\n",
      "  0.01459894  0.00357573  0.00920605  0.00909018  0.0108687   0.00629312\n",
      "  0.00499508  0.00619917  0.00378188  0.00438855  0.00456876  0.0053844\n",
      "  0.00670384  0.00818545  0.00676038  0.00467808  0.00554435  0.00451028\n",
      "  0.00774034  0.00671159  0.00852312  0.00431312  0.00446106  0.00603171\n",
      "  0.01379735  0.00775044  0.00593915  0.00386085  0.00487116  0.00579917\n",
      "  0.00568956  0.00830241  0.006146    0.00838277  0.00178496  0.00817382\n",
      "  0.00539611  0.00390004  0.00901921  0.00608844  0.01078675  0.00647919\n",
      "  0.00903231  0.00860742  0.00922771  0.01312853  0.00723216  0.00480543\n",
      "  0.00869647  0.00708772  0.00864618  0.00856548  0.00326522  0.00337232\n",
      "  0.00553833  0.00765193  0.0088991   0.00789911  0.00526535  0.00563512\n",
      "  0.01080127  0.00830858  0.00404886  0.00810101  0.00549017  0.00751939\n",
      "  0.00343227  0.00771686  0.00765792  0.00731029  0.00644126  0.00720088\n",
      "  0.00423078  0.01106346  0.00388251  0.00139766  0.00417372  0.005079\n",
      "  0.00434738  0.00971553  0.00762526  0.00405789  0.00477259  0.005879\n",
      "  0.00746355  0.00719217  0.00921374  0.00525271  0.00538705  0.00595801\n",
      "  0.00880436  0.00483262  0.00747514  0.00518961  0.00955685  0.00587491\n",
      "  0.00759616  0.00869222  0.00319615  0.00454095  0.00924277  0.00364207]\n",
      "\n",
      "Logistic Regression\n",
      "Average Hit Rate = 47.807%\n",
      " \n",
      "Naive Bayes\n",
      "Average Hit Rate = 45.6754%\n",
      "\n",
      "K Neighbors\n",
      "Average Hit Rate = 50.386%\n",
      "\n",
      "Decision Tree\n",
      "Average Hit Rate = 48.8246%\n",
      "\n",
      "Support Vector Machine\n",
      "Average Hit Rate = 45.0965%\n",
      "\n",
      "Code=I, Type=d, lags=[100, 100, 100], k_fold=10\n",
      "[ 0.00535628  0.00553633  0.00242452  0.00300733  0.00258341  0.00448813\n",
      "  0.00311887  0.00140012  0.00051242  0.00330713  0.00172488  0.00467325\n",
      "  0.00456494  0.00050196  0.0074544   0.00368296  0.00090426  0.00517088\n",
      "  0.00333581  0.00285357  0.0014607   0.00434413  0.00603063  0.00169973\n",
      "  0.00060815  0.00279687  0.00359925  0.00310118  0.00435564  0.0053669\n",
      "  0.00632449  0.00320854  0.00427855  0.00322547  0.00065883  0.00191997\n",
      "  0.00418806  0.00092236  0.00370914  0.00164704  0.00299493  0.00234216\n",
      "  0.00093619  0.00235278  0.00139561  0.00830257  0.00146786  0.00564871\n",
      "  0.00277753  0.00395776  0.00212707  0.0036911   0.00239112  0.00304388\n",
      "  0.00239619  0.00318083  0.00405031  0.00409792  0.00293746  0.0011823\n",
      "  0.00490603  0.00207155  0.00295482  0.00362739  0.00255887  0.00327141\n",
      "  0.00518117  0.00345415  0.00233535  0.00511331  0.00287459  0.00212215\n",
      "  0.00394292  0.00301888  0.00501521  0.00380761  0.00473324  0.00264878\n",
      "  0.00268981  0.00502961  0.00213577  0.00508061  0.00569285  0.00033882\n",
      "  0.0024079   0.00405585  0.00484557  0.00661759  0.00352313  0.00372926\n",
      "  0.00436308  0.00416666  0.00183929  0.00235796  0.00181603  0.00261454\n",
      "  0.00289322  0.00601168  0.00451848  0.0007015   0.0012083   0.00082465\n",
      "  0.00412176  0.00183801  0.00378256  0.00159703  0.0038331   0.00160753\n",
      "  0.00241272  0.00251314  0.00186202  0.00235803  0.00459729  0.00393258\n",
      "  0.00091996  0.00333392  0.00430922  0.00163024  0.00260336  0.00258167\n",
      "  0.00342001  0.00306735  0.00447739  0.00169605  0.00468199  0.00226252\n",
      "  0.00097682  0.00239003  0.00302776  0.00285856  0.00512623  0.\n",
      "  0.00752106  0.00197094  0.00320897  0.00106667  0.00104075  0.00267382\n",
      "  0.00285807  0.00249031  0.00438754  0.0006902   0.00306055  0.00583639\n",
      "  0.00327545  0.00295392  0.00267601  0.00447503  0.00066385  0.00583246\n",
      "  0.00421572  0.00065255  0.00259536  0.00073705  0.00201663  0.00548375\n",
      "  0.00230801  0.00263259  0.00493315  0.00466993  0.00525348  0.01065371\n",
      "  0.00098462  0.00446696  0.00461139  0.00219266  0.00380302  0.00084136\n",
      "  0.00459981  0.00122353  0.00428819  0.00615737  0.00336195  0.00249363\n",
      "  0.00252696  0.00107928  0.00724481  0.00154816  0.00097198  0.00167385\n",
      "  0.00252568  0.          0.00152658  0.00303806  0.00451401  0.00322618\n",
      "  0.0029175   0.00299385  0.00515636  0.00504769  0.00476627  0.00626817\n",
      "  0.00437621  0.00262998  0.00172033  0.0046039   0.00628389  0.00303143\n",
      "  0.00324242  0.00180855  0.00265538  0.00528502  0.00141322  0.00606886\n",
      "  0.00083899  0.00547907  0.00300153  0.00299181  0.00292473  0.00516184\n",
      "  0.00369199  0.00292282  0.00442623  0.00218221  0.00508995  0.00288395\n",
      "  0.00413761  0.0019532   0.00487282  0.00167388  0.00429464  0.00465546\n",
      "  0.0028686   0.00321769  0.00409136  0.00485132  0.00240249  0.00374196\n",
      "  0.00062991  0.00235743  0.00400211  0.0049265   0.00230903  0.00347865\n",
      "  0.00683328  0.00120471  0.00202618  0.00511243  0.00132124  0.00421917\n",
      "  0.00504865  0.00247252  0.00298384  0.00644082  0.00202674  0.0022427\n",
      "  0.00174795  0.00261513  0.00398307  0.00720234  0.00285307  0.00393551\n",
      "  0.00282748  0.0039229   0.00137473  0.00226193  0.00207914  0.00439732\n",
      "  0.004353    0.00277937  0.00235052  0.00212707  0.00219179  0.00570852\n",
      "  0.00226278  0.00242999  0.00293369  0.0057634   0.00390228  0.00328036\n",
      "  0.0029306   0.0018078   0.00255227  0.00630238  0.00591896  0.0042973\n",
      "  0.00308843  0.00655175  0.00362471  0.00369397  0.          0.00411068\n",
      "  0.00491098  0.00277159  0.00096583  0.00071521  0.00119216  0.00379881\n",
      "  0.0060262   0.00106667  0.00378531  0.00420276  0.00249617  0.00286896\n",
      "  0.00184087  0.00805702  0.00425641  0.00404707  0.0136366   0.00496433]\n",
      "\n",
      "Logistic Regression\n",
      "Average Hit Rate = 50.6154%\n",
      " \n",
      "Naive Bayes\n",
      "Average Hit Rate = 50.1993%\n",
      "\n",
      "K Neighbors\n",
      "Average Hit Rate = 44.3531%\n",
      "\n",
      "Decision Tree\n",
      "Average Hit Rate = 53.5629%\n",
      "\n",
      "Support Vector Machine\n",
      "Average Hit Rate = 50.3601%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml = ML(AQ())\n",
    "ml.ml(\"I\", \"d\", [1, 1, 1], 10)\n",
    "ml.ml(\"I\", \"d\", [5, 5, 5], 10)\n",
    "ml.ml(\"I\", \"d\", [10, 10, 10], 10)\n",
    "ml.ml(\"I\", \"d\", [20, 20, 20], 10)\n",
    "ml.ml(\"I\", \"d\", [50, 50, 50], 10)\n",
    "ml.ml(\"I\", \"d\", [100, 100, 100], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
